{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH98jf5368F/b2ZX78kXF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muharyaanandas/CNN-Waste-Classification/blob/main/MobileNet_SGD%20(Stochastic%20Gradient%20Descent).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnYpYUeE0ls2",
        "outputId": "a7f19794-5747-41ba-bac5-d2c7c32127ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read all image types\n",
        "\n",
        "def list_images(basePath, contains=None):\n",
        "    # return the set of files that are valid\n",
        "    return list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"), contains=contains)\n",
        "\n",
        "def list_files(basePath, validExts=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"), contains=None):\n",
        "    # loop over the directory structure\n",
        "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
        "        # loop over the filenames in the current directory\n",
        "        for filename in filenames:\n",
        "            # if the contains string is not none and the filename does not contain\n",
        "            # the supplied string, then ignore the file\n",
        "            if contains is not None and filename.find(contains) == -1:\n",
        "                continue\n",
        "\n",
        "            # determine the file extension of the current file\n",
        "            ext = filename[filename.rfind(\".\"):].lower()\n",
        "\n",
        "            # check to see if the file is an image and should be processed\n",
        "            if ext.endswith(validExts):\n",
        "                # construct the path to the image and yield it\n",
        "                imagePath = os.path.join(rootDir, filename).replace(\" \", \"\\\\ \")\n",
        "                yield imagePath"
      ],
      "metadata": {
        "id": "dRd90jqY0tQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "-cRMjhcG0v5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data path\n",
        "data_dir = '/content/drive/MyDrive/Klasifikasi_Sampah/Dataset'\n",
        "dirs = os.listdir(data_dir)\n",
        "\n",
        "# Initialize a dictionary to store image counts\n",
        "image_counts = {}\n",
        "\n",
        "# Load images and labels\n",
        "data_list = []\n",
        "labels = []\n",
        "class_label = 0\n",
        "for dir_name in dirs:\n",
        "    path = os.path.join(data_dir, dir_name)\n",
        "    image_files = glob.glob(os.path.join(path, '*'))\n",
        "    image_count = 0\n",
        "    for image_file in image_files:\n",
        "        img = cv2.imread(image_file)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            data_list.append(img)\n",
        "            labels.append(class_label)\n",
        "            image_count += 1\n",
        "    image_counts[dir_name] = image_count  # Store the count of images per category\n",
        "    class_label += 1\n",
        "\n",
        "# Print the total images for each category\n",
        "for category, count in image_counts.items():\n",
        "    print(f\"Total {category} images: {count}\")\n",
        "\n",
        "data_array = np.array(data_list) / 255.0\n",
        "labels_array = np.array(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy96RQc60zEO",
        "outputId": "2f1b6577-8ebb-4e9b-87f6-38c173dcab53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Organik images: 100\n",
            "Total Anorganik images: 109\n",
            "Total B3 images: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_binarizer = LabelBinarizer()\n",
        "encoded_labels = label_binarizer.fit_transform(labels_array)\n",
        "\n",
        "# Splitting dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data_array, encoded_labels, test_size=0.2, stratify=encoded_labels, random_state=24)\n",
        "\n",
        "# Augmentasi data\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Model MobileNet\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = True  # Unfreeze the base model for fine-tuning\n",
        "\n",
        "# Membangun model di atas MobileNet\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKhjVTz9011E",
        "outputId": "51b6469b-e882-4933-df32-f81d1fdd0e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kompilasi model dengan optimizer SGD\n",
        "model.compile(\n",
        "    optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "7A90uNIT05Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint_filepath = '/content/drive/MyDrive/Klasifikasi_Sampah/MobileNet/Epoch_35_SGD/Model2.hdf5'\n",
        "save_model = ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Melatih model\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, Y_train, batch_size=32),\n",
        "    validation_data=(X_test, Y_test),\n",
        "    epochs=35,\n",
        "    callbacks=[save_model, reduce_lr]\n",
        ")\n",
        "\n",
        "print(\"Highest Training Accuracy:\", max(history.history['accuracy']))\n",
        "print(\"Highest Validation Accuracy:\", max(history.history['val_accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WvsuJxb08WJ",
        "outputId": "7a754473-9c02-433d-e429-d747799464ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "8/8 [==============================] - ETA: 0s - loss: 1.6741 - accuracy: 0.3306"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 65s 7s/step - loss: 1.6741 - accuracy: 0.3306 - val_loss: 1.2095 - val_accuracy: 0.5323 - lr: 0.0100\n",
            "Epoch 2/35\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.9763 - accuracy: 0.6048 - val_loss: 1.5786 - val_accuracy: 0.3710 - lr: 0.0100\n",
            "Epoch 3/35\n",
            "8/8 [==============================] - 60s 7s/step - loss: 0.6377 - accuracy: 0.7581 - val_loss: 0.9233 - val_accuracy: 0.5645 - lr: 0.0100\n",
            "Epoch 4/35\n",
            "8/8 [==============================] - 59s 7s/step - loss: 0.6357 - accuracy: 0.7419 - val_loss: 1.1881 - val_accuracy: 0.4516 - lr: 0.0100\n",
            "Epoch 5/35\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.5164 - accuracy: 0.7863 - val_loss: 1.0348 - val_accuracy: 0.5806 - lr: 0.0100\n",
            "Epoch 6/35\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.2412 - accuracy: 0.9194 - val_loss: 1.1305 - val_accuracy: 0.6129 - lr: 0.0100\n",
            "Epoch 7/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.2768 - accuracy: 0.9032 - val_loss: 1.1775 - val_accuracy: 0.6290 - lr: 0.0100\n",
            "Epoch 8/35\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.3023 - accuracy: 0.8992 - val_loss: 1.2146 - val_accuracy: 0.6774 - lr: 0.0100\n",
            "Epoch 9/35\n",
            "8/8 [==============================] - 59s 7s/step - loss: 0.4667 - accuracy: 0.8548 - val_loss: 1.7333 - val_accuracy: 0.5806 - lr: 0.0020\n",
            "Epoch 10/35\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.3749 - accuracy: 0.8710 - val_loss: 1.7315 - val_accuracy: 0.5806 - lr: 0.0020\n",
            "Epoch 11/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.2708 - accuracy: 0.9073 - val_loss: 1.9521 - val_accuracy: 0.5323 - lr: 0.0020\n",
            "Epoch 12/35\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.1417 - accuracy: 0.9476 - val_loss: 1.7629 - val_accuracy: 0.5806 - lr: 0.0020\n",
            "Epoch 13/35\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.1185 - accuracy: 0.9758 - val_loss: 1.5636 - val_accuracy: 0.6290 - lr: 0.0020\n",
            "Epoch 14/35\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.1126 - accuracy: 0.9677 - val_loss: 1.4510 - val_accuracy: 0.6129 - lr: 4.0000e-04\n",
            "Epoch 15/35\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.1073 - accuracy: 0.9597 - val_loss: 1.3474 - val_accuracy: 0.6290 - lr: 4.0000e-04\n",
            "Epoch 16/35\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.1435 - accuracy: 0.9556 - val_loss: 1.2493 - val_accuracy: 0.6290 - lr: 4.0000e-04\n",
            "Epoch 17/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.0836 - accuracy: 0.9758 - val_loss: 1.1737 - val_accuracy: 0.6613 - lr: 4.0000e-04\n",
            "Epoch 18/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.1259 - accuracy: 0.9597 - val_loss: 1.1060 - val_accuracy: 0.6613 - lr: 4.0000e-04\n",
            "Epoch 19/35\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0708 - accuracy: 0.9839 - val_loss: 1.0348 - val_accuracy: 0.6452 - lr: 8.0000e-05\n",
            "Epoch 20/35\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.0766 - accuracy: 0.9839 - val_loss: 0.9796 - val_accuracy: 0.6452 - lr: 8.0000e-05\n",
            "Epoch 21/35\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.0825 - accuracy: 0.9758 - val_loss: 0.9365 - val_accuracy: 0.6452 - lr: 8.0000e-05\n",
            "Epoch 22/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.0893 - accuracy: 0.9758 - val_loss: 0.9033 - val_accuracy: 0.6774 - lr: 8.0000e-05\n",
            "Epoch 23/35\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.0766 - accuracy: 0.9798 - val_loss: 0.8795 - val_accuracy: 0.6774 - lr: 8.0000e-05\n",
            "Epoch 24/35\n",
            "8/8 [==============================] - 58s 7s/step - loss: 0.1006 - accuracy: 0.9556 - val_loss: 0.8505 - val_accuracy: 0.6774 - lr: 8.0000e-05\n",
            "Epoch 25/35\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.1049 - accuracy: 0.9718 - val_loss: 0.8305 - val_accuracy: 0.6935 - lr: 8.0000e-05\n",
            "Epoch 26/35\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.0448 - accuracy: 0.9798 - val_loss: 0.8182 - val_accuracy: 0.6935 - lr: 8.0000e-05\n",
            "Epoch 27/35\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.0741 - accuracy: 0.9758 - val_loss: 0.8114 - val_accuracy: 0.7097 - lr: 8.0000e-05\n",
            "Epoch 28/35\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0550 - accuracy: 0.9798 - val_loss: 0.8054 - val_accuracy: 0.7097 - lr: 8.0000e-05\n",
            "Epoch 29/35\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.1286 - accuracy: 0.9556 - val_loss: 0.7996 - val_accuracy: 0.7419 - lr: 8.0000e-05\n",
            "Epoch 30/35\n",
            "8/8 [==============================] - 60s 7s/step - loss: 0.0658 - accuracy: 0.9879 - val_loss: 0.7936 - val_accuracy: 0.7581 - lr: 8.0000e-05\n",
            "Epoch 31/35\n",
            "8/8 [==============================] - 57s 7s/step - loss: 0.0716 - accuracy: 0.9677 - val_loss: 0.7870 - val_accuracy: 0.7742 - lr: 8.0000e-05\n",
            "Epoch 32/35\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0868 - accuracy: 0.9637 - val_loss: 0.7836 - val_accuracy: 0.7742 - lr: 8.0000e-05\n",
            "Epoch 33/35\n",
            "8/8 [==============================] - 59s 7s/step - loss: 0.0857 - accuracy: 0.9718 - val_loss: 0.7786 - val_accuracy: 0.7742 - lr: 8.0000e-05\n",
            "Epoch 34/35\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.7729 - val_accuracy: 0.7742 - lr: 8.0000e-05\n",
            "Epoch 35/35\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.1256 - accuracy: 0.9637 - val_loss: 0.7707 - val_accuracy: 0.7742 - lr: 8.0000e-05\n",
            "Highest Training Accuracy: 0.9879032373428345\n",
            "Highest Validation Accuracy: 0.774193525314331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model\n",
        "best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "pred_test = best_model.predict(X_test)\n",
        "pred_test_labels = np.argmax(pred_test, axis=1)\n",
        "y_test_labels = np.argmax(Y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_test_labels, pred_test_labels))\n",
        "print(\"Accuracy : \", accuracy_score(y_test_labels, pred_test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V3zsSO11HW-",
        "outputId": "84d1a9e3-b6ae-439d-d247-15693c6dce38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 4s 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.80      0.86        20\n",
            "           1       0.73      0.73      0.73        22\n",
            "           2       0.70      0.80      0.74        20\n",
            "\n",
            "    accuracy                           0.77        62\n",
            "   macro avg       0.79      0.78      0.78        62\n",
            "weighted avg       0.79      0.77      0.78        62\n",
            "\n",
            "Accuracy :  0.7741935483870968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to file\n",
        "tflite_model_filepath = '/content/drive/MyDrive/Klasifikasi_Sampah/MobileNet/Epoch_35_SGD/model.tflite'\n",
        "with open(tflite_model_filepath, 'wb') as file:\n",
        "    file.write(tflite_model)\n",
        "\n",
        "print(f\"Model saved as .hdf5 at {checkpoint_filepath}\")\n",
        "print(f\"Model saved as .tflite at {tflite_model_filepath}\")"
      ],
      "metadata": {
        "id": "hyAYJjDV1K7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}